{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import climatedata_functions as climf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import date, timedelta, datetime\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the weather data\n",
    "\n",
    "This notebook joins weather data of different time points (0:00, 6:00, 12:00, and 18:00) for seven days. The weather data format is in a column ('t' for temperature, 'si10' for wind, and 'dswrf' for radiation) containing seven values (day of the sampling, 1, 2, 3, 4, 5, 6 days before sampling). This notebook will put the values in only one column containing all 28 values for one parameter for all dates and time points beginning with the data of 6 days before sampling (0:00, 6:00, 12:00, 18:00). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/metadata_temp_12_01_06_complete_without_a.csv\") # Load metadata for geographic locations from a CSV file\n",
    "features = ['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1','longitude_trans','x_grid','y_grid','temp_01'] # Define a list of columns to drop from the metadata DataFrame\n",
    "temp_00 = pd.read_csv(\"../data/temp_00.csv\") # Load the temperature data for the 00:00 time from a CSV file\n",
    "temp_18 = pd.read_csv(\"../data/temp_18.csv\") # Load the temperature data for the 18:00 time from a CSV file\n",
    "metadata.drop(features, axis=1, inplace=True) # Drop the columns defined in the features list from the metadata DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the temperature data for 00:00 hour with the metadata based on unique IDs\n",
    "metadata = metadata.merge(temp_00[['uid','t_0']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "# Merge the temperature data for 18:00 hour with the metadata based on unique IDs\n",
    "metadata = metadata.merge(temp_18[['uid','t_18']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "# Rename columns\n",
    "metadata = metadata.rename(columns={'temp_06': 't_6','temp_12': 't_12'})\n",
    "\n",
    "# Define a list of columns to convert from strings to lists of numbers\n",
    "features = ['t_0', 't_6', 't_12', 't_18']\n",
    "\n",
    "# Convert the specified columns from strings to lists of numbers\n",
    "temp = climf.convert_str_to_list(metadata, features)\n",
    "\n",
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the temperature data to a CSV file\n",
    "temp.to_csv(f'../data/temperature.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "# Iterate over the rows of the temp DataFrame using a progress bar\n",
    "for row in (pbar := tqdm(temp.itertuples(), total=len(temp))):\n",
    "    print(row)                                                   # Print the current row for debugging purposes\n",
    "    time_ser = climf.join_time_values(row.t_0, row.t_6, row.t_12, row.t_18) # Combine the temperature values for different times into a time series\n",
    "    temp.loc[temp['uid'] == row.uid, ['temp']] = str(time_ser) # Update the 'temp' column for the current row with the time series as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns for individual temperature values, since we have combined them into time series\n",
    "temp = temp.drop(['t_12', 't_6', 't_0', 't_18'], axis=1)\n",
    "# Write the resulting DataFrame to a CSV file\n",
    "temp.to_csv('../data/temperature_series.csv', index=False)\n",
    "temp.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join with data 14days prior sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file containing the temperature data for the 't_18' time step\n",
    "temp_before = pd.read_csv(\"../data/t_18_14_15_d_before.csv\")\n",
    "# Define the list of features to drop from the DataFrame\n",
    "features = ['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'temp_01', 'temp_12', 'temp_06', 'dswrf_0']\n",
    "# Drop the specified features from the DataFrame\n",
    "temp_before = temp_before.drop(features, axis = 1)\n",
    "temp_before.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the temperature DataFrame with the 'temp_before' DataFrame on the 'uid', 't_0', 't_6', 't_12', 't_18', 'x_grid', and 'y_grid' columns\n",
    "temp = temp.merge(temp_before[['uid','t_0', 't_6', 't_12', 't_18', 'x_grid', 'y_grid']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there ws one erronous line --> the data for that was dowloaded again with this code:\n",
    "days = 2  #how many days to go back?\n",
    "hour = 12 #which our of the day (UTS time!!!)# we want to test: 6,12,18,24\n",
    "param_layer = ':TMP:surface' # options: ':TMP:surface', ' \":DSWRF:surface\"'  surface temperature, #available parameters and layes: https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfsfcf00.grib2.shtml\n",
    "forecast_param = 't'#for temperature: 't', for wind:10maboveground: 'si10', for dswrf: 'dswrf' for name of the column in the metadata and the grib2 data\n",
    "\n",
    "\n",
    "#from tqdm import tqdm\n",
    "#pbar.set_description(f\"Processing {start_date} --> {temp_list[0][0]}\")\n",
    "\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "#make empty list to store the dates already sampled\n",
    "start_date = temp.date.iloc[4853]#4853\n",
    "date_index_list = temp.index[temp.date == start_date]#list with all the indexes of dates with the same date\n",
    "temp_list = [[0] * days for i in range(len(date_index_list))]#make list of lists to store the values inside\n",
    "start_date = climf.get_start_date(start_date)#formate to time object\n",
    "print(start_date)\n",
    "for x in range(days):\n",
    "    count = 0\n",
    "    #x = x*2 (if we want to take only every second day)\n",
    "    day_date = start_date - timedelta(days=x+14)\n",
    "    #ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "    ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "    for index in date_index_list:\n",
    "        x_grid = temp.x_grid[index]\n",
    "        y_grid = temp.y_grid[index]\n",
    "        if stop == True:\n",
    "            temp_list[count][x] = np.nan\n",
    "        else:\n",
    "            temp_list[count][x] = ds[x_grid][y_grid]\n",
    "        count += 1\n",
    "        if x == days-1 and index == date_index_list[len(date_index_list)-1]:#if condition is met put the values in the metadata file\n",
    "            for i in range(len(temp_list)):                    \n",
    "                temp[forecast_param+'_'+str(hour)].loc[date_index_list[i]] = temp_list[i] #not index but  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['t_0', 't_6', 't_12', 't_18'] # list of feature names being defined and to be converted to string format\n",
    "temp = climf.convert_to_str(temp, features) # Convert the specified features in the DataFrame to string format\n",
    "temp = climf.convert_str_to_list(temp, features) # Convert the specified features in the DataFrame to a list format\n",
    "temp.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature\n",
    "# loop through each row in the temp dataframe\n",
    "for row in (pbar := tqdm(temp.itertuples(), total=len(temp))):\n",
    "    print(row)\n",
    "    # join the temperature values for each time period and store in a string format\n",
    "    time_ser = climf.join_time_values(row.t_0, row.t_6, row.t_12, row.t_18)\n",
    "    # add a new column to temp for the joined time series\n",
    "    temp.loc[temp['uid'] == row.uid, ['temp_14_15d_before']] = str(time_ser) \n",
    "temp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns that we do not need from the temp dataframe\n",
    "temp = temp.drop(['t_12', 't_6', 't_0', 't_18', 'x_grid', 'y_grid'], axis=1)\n",
    "# Saving the resulting temp dataframe to a CSV file\n",
    "temp.to_csv('../data/temperature_series.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the wind speed data files\n",
    "wind_0 = pd.read_csv(\"../data/wind_0.csv\")\n",
    "wind_6 = pd.read_csv(\"../data/metadata_si10_6_complete.csv\")\n",
    "wind_12 = pd.read_csv(\"../data/metadata_si10_12_complete.csv\")\n",
    "wind_18 = pd.read_csv(\"../data/metadata_si10_18_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge wind data on uid and validate that there is a 1:1 mapping\n",
    "wind = wind_0.merge(wind_6[['uid','si10_6']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "wind = wind.merge(wind_12[['uid','si10_12']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "wind = wind.merge(wind_18[['uid','si10_18']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "\n",
    "# convert si10 values to lists for easier manipulation\n",
    "features = ['si10_0','si10_6','si10_12','si10_18']\n",
    "wind = climf.convert_str_to_list(wind, features)\n",
    "wind.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wind\n",
    "# Iterate through rows of the wind dataframe and join wind values at different times for each row\n",
    "for row in (pbar := tqdm(wind.itertuples(), total=len(wind))):\n",
    "    # Join wind values at different times into a time series for the current row\n",
    "    time_ser = climf.join_time_values(row.si10_0, row.si10_6, row.si10_12, row.si10_18)\n",
    "    # Update the 'wind' column of the current row with the time series as a string\n",
    "    wind.loc[wind['uid'] == row.uid, ['wind']] = str(time_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns with wind speed data\n",
    "wind = wind.drop(['si10_0','si10_6','si10_12','si10_18'], axis=1)\n",
    "# save the DataFrame as a CSV file\n",
    "wind.to_csv('../data/wind_series.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv files for Radiations for differant times of the day at 0,6,12,17 and 18 hours\n",
    "rad_0 = pd.read_csv(\"../data/metadata_dswrf_0.csv\")\n",
    "rad_6 = pd.read_csv(\"../data/metadata_dswrf_6.csv\")\n",
    "rad_12 = pd.read_csv(\"../data/metadata_dswrf_12.csv\")\n",
    "rad_17 = pd.read_csv(\"../data/metadata_dswrf_17.csv\")\n",
    "rad_18 = pd.read_csv(\"../data/metadata_dswrf_18.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes into one for radiation\n",
    "rad = rad_17.merge(rad_0[['uid','dswrf_0']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "#rad = rad.merge(rad_6[['uid','dswrf_6']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "rad = rad.merge(rad_18[['uid','dswrf_18']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "#rad = rad.merge(rad_12[['uid','dswrf_12']] , how=\"inner\", on='uid' , validate=\"1:1\")\n",
    "\n",
    "# Convert radiation values to string and store in list format\n",
    "features = ['dswrf_0','dswrf_17','dswrf_18']#add later: 'dswrf_12','dswrf_6',\n",
    "rad = climf.convert_to_str(rad, features)\n",
    "rad = climf.convert_str_to_list(rad, features)\n",
    "rad.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#radiation\n",
    "# Loop through each row of the rad dataframe using tqdm progress bar\n",
    "for row in (pbar := tqdm(rad.itertuples(), total=len(rad))):\n",
    "    #For each row, join the dswrf values for 0, 17, and 18 hours\n",
    "    time_ser = climf.join_time_values_three(row.dswrf_0, row.dswrf_17, row.dswrf_18)# add laterthe right one for 12 o'clock!!!!!!\n",
    "    # Store the resulting time series as a string in a new column of the dataframe called 'rad_0_17_18'\n",
    "    rad.loc[rad['uid'] == row.uid, ['rad_0_17_18']] = str(time_ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns from the rad DataFrame and update the rad variable\n",
    "features = ['x_grid', 'y_grid','longitude_trans', 'Unnamed: 0.1', 'Unnamed: 0' ]\n",
    "rad = rad.drop(features, axis=1)\n",
    "rad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe as a CSV file for radiation data\n",
    "rad.to_csv('../data/radiation.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74c0fefd5bdbab4f170fbec01c2ecde304160225294ef8f5fadf2990b43ed0f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
