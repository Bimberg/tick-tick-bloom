{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NOAA HRRR is a real-time 3km resolution, hourly updated, cloud-resolving, convection-allowing atmospheric model, initialized by 3km grids with 3km radar assimilation.\n",
    "\n",
    "This notebook provides an example of accessing HRRR data, including (1) finding the data file corresponding to a date and time, (2) retrieving a portion of that file from blob storage which includes the surface temperature variable, (3) opening the file using the xarray library, and (4) rendering an image of the forecast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is documented at http://aka.ms/ai4edata-hrrr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import climatedata_functions as climf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/metadata.csv\")\n",
    "ds = climf.get_ds()#only works with recent dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make metadafile with gridpoints\n",
    "\n",
    "In the next cell the grid points are calculated. This needs to be executed only once and then the file is saved and then just loaded if the notebook is executed anther time. (Note: takes 6-8 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform coordinates for longitude\n",
    "metadata['longitude_trans'] = metadata['longitude']+360 \n",
    "#add columns for gridpoints\n",
    "metadata['x_grid'] = ''\n",
    "metadata['y_grid'] = ''\n",
    "\n",
    "#make new metadatafile and save as cvs \n",
    "#metadata_new = climf.save_grids(metadata, ds) #(takes approx 6 minutes)\n",
    "#metadata_new.to_csv('../data/metadata_grids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>longitude_trans</th>\n",
       "      <th>x_grid</th>\n",
       "      <th>y_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>273.569133</td>\n",
       "      <td>570</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>238.490000</td>\n",
       "      <td>550</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>281.121566</td>\n",
       "      <td>488</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   uid   latitude   longitude        date  split  \\\n",
       "0           0  aabm  39.080319  -86.430867  2018-05-14  train   \n",
       "1           1  aabn  36.559700 -121.510000  2016-08-31   test   \n",
       "2           2  aacd  35.875083  -78.878434  2020-11-19  train   \n",
       "\n",
       "   longitude_trans  x_grid  y_grid  \n",
       "0       273.569133     570    1217  \n",
       "1       238.490000     550     192  \n",
       "2       281.121566     488    1455  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load new metadata file that includes the gridpoints\n",
    "metadata = pd.read_csv(\"../data/metadata_grids.csv\")\n",
    "metadata.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get temperatures for gridpoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function that gets the mean/median temperature for one date for all the places sampled at that date (to save time) and the previos x days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata = pd.read_csv(\"../data/metadata_temp_12_01_06_complete_without_a.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data list:**\n",
    "\n",
    "**Radiation**\n",
    "* DSWRF:surface\t(Downward Short-Wave Radiation Flux [W/m^2])\n",
    "* DLWRF:surface\t(Downward Long-Wave Rad. Flux [W/m^2])\n",
    "\n",
    "**Wind**\n",
    "* WIND:10 m above ground (0-0 day max f\tWind Speed [m/s])\n",
    "* UGRD:10 m above ground (analysis\tU-Component of Wind [m/s]) --> also avalable as 0-0 day max)\n",
    "* VGRD:10 m above ground (analysis\tV-Component of Wind [m/s]) --> also avalable as 0-0 day max)\n",
    "\n",
    "**Temperature**\n",
    "* maybe think abut getting a different time (UTS vs time at a specific place...)\n",
    "\n",
    "We want to get the model for hours: 6, 12, 18, and 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define  download parameters\n",
    "days = 7  #how many days to go back?\n",
    "hour = 0 #which our of the day (UTS time!!!)# we want to test: 6,12,18,24\n",
    "param_layer = ':DSWRF:surface' # options: ':TMP:surface', ' \":DSWRF:surface\"'  surface temperature, #available parameters and layes: https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfsfcf00.grib2.shtml\n",
    "forecast_param = 'dswrf'#for temperature: 't', for wind:10maboveground: 'si10', for dswrf: 'dswrf' for name of the column in the metadata and the grib2 data\n",
    "#dswrf = Downward Short-Wave Radiation Flux [W/m^2] https://www.goes-r.gov/products/baseline-DSR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "#pbar.set_description(f\"Processing {start_date} --> {temp_list[0][0]}\")\n",
    "\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "#make empty list to store the dates already sampled\n",
    "done_list = []\n",
    "metadata[forecast_param+'_'+str(hour)] = '' #create new column to store the data \n",
    "for idx in metadata.index: #takes first element in metadata list\n",
    "    start_date = metadata.date[idx]\n",
    "    date_index_list = metadata.index[metadata.date == start_date]#list with all the indexes of dates with the same date\n",
    "    if start_date not in done_list:#if data for the given date was already downloaded, this row will be skipped\n",
    "        temp_list = [[0] * days for i in range(len(date_index_list))]#make list of lists to store the values inside\n",
    "        done_list.append(start_date)#list of dates already samples\n",
    "        start_date = climf.get_start_date(start_date)#formate to time object\n",
    "        print(start_date)\n",
    "        for x in range(days):\n",
    "            count = 0\n",
    "            #x = x*2 (if we want to take only every second day)\n",
    "            day_date = start_date - timedelta(days=x)\n",
    "            #ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "            ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "            for index in date_index_list:\n",
    "                x_grid = metadata.x_grid[index]\n",
    "                y_grid = metadata.y_grid[index]\n",
    "                if stop == True:\n",
    "                    temp_list[count][x] = np.nan\n",
    "                else:\n",
    "                    temp_list[count][x] = ds[x_grid][y_grid]\n",
    "                count += 1\n",
    "                if x == days-1 and index == date_index_list[len(date_index_list)-1]:#if condition is met put the values in the metadata file\n",
    "                    for i in range(len(temp_list)):                    \n",
    "                        metadata[forecast_param+'_'+str(hour)].loc[date_index_list[i]] = temp_list[i] #not index but  \n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv(f'../data/metadata_{forecast_param}_{str(hour)}_complete.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the download was interupted the code in the next cell can be used to continue with the download. Since the dates already dowloaded are saved in 'done_list', it can continue from that withouth starting from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done_list.pop()#remove last element (in case it didn work with that)\n",
    "#len(done_list)#how many dates are already inside (1637 unique dates in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.simplefilter(action='ignore')\n",
    "\n",
    "# for idx in metadata.index: #takes first element in metadata list\n",
    "#     start_date = metadata.date[idx]\n",
    "#     date_index_list = metadata.index[metadata.date == start_date]#list with all the indexes of dates with the same date\n",
    "#     if start_date not in done_list:#only do if this date wasnt used before\n",
    "#         temp_list = [[0] * days for i in range(len(date_index_list))]#make list of lists to store the values inside\n",
    "#         done_list.append(start_date)#list of dates already samples\n",
    "#         start_date = climf.get_start_date(start_date)#formate to time object\n",
    "#         print(start_date)\n",
    "#         for x in range(days):\n",
    "#             count = 0\n",
    "#             day_date = start_date - timedelta(days=x)\n",
    "#             ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "#             for index in date_index_list:\n",
    "#                 x_grid = metadata.x_grid[index]\n",
    "#                 y_grid = metadata.y_grid[index]\n",
    "#                 if stop == True:\n",
    "#                     temp_list[count][x] = np.nan\n",
    "#                 else:\n",
    "#                     temp_list[count][x] = ds[x_grid][y_grid]\n",
    "#                 count += 1\n",
    "#                 if x == days-1 and index == date_index_list[len(date_index_list)-1]:#if condition is met put the values in the metadata file\n",
    "#                     for i in range(len(temp_list)):                    \n",
    "#                         metadata[forecast_param+'_'+str(hour)].loc[date_index_list[i]] = temp_list[i] #not index but  \n",
    "#     else:\n",
    "#         continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata.to_csv(f'../data/metadata_{forecast_param}_{str(hour)}_complete.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get temperature 14 and 10 days before sampling date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>longitude_trans</th>\n",
       "      <th>x_grid</th>\n",
       "      <th>y_grid</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>273.569133</td>\n",
       "      <td>570</td>\n",
       "      <td>1217</td>\n",
       "      <td>[286.12405, 286.0968]</td>\n",
       "      <td>[286.211, 286.15918]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid   latitude  longitude        date  split  longitude_trans  x_grid  \\\n",
       "0  aabm  39.080319 -86.430867  2018-05-14  train       273.569133     570   \n",
       "\n",
       "   y_grid                    t_0                   t_6  \n",
       "0    1217  [286.12405, 286.0968]  [286.211, 286.15918]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(\"../data/t_6_14_15_d_before.csv\", index_col=False)\n",
    "features = ['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'temp_01', 'temp_12', 'temp_06', 'dswrf_0',]\n",
    "metadata = metadata.drop(features, axis = 1)\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define  download parameters\n",
    "days = 2  #how many days to go back?\n",
    "hour = 12 #which our of the day (UTS time!!!)# we want to test: 6,12,18,24\n",
    "param_layer = ':TMP:surface' # options: ':TMP:surface', ' \":DSWRF:surface\"'  surface temperature, #available parameters and layes: https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfsfcf00.grib2.shtml\n",
    "forecast_param = 't'#for temperature: 't', for wind:10maboveground: 'si10', for dswrf: 'dswrf' for name of the column in the metadata and the grib2 data\n",
    "before = 14 # how many days before sampling date\n",
    "#dswrf = Downward Short-Wave Radiation Flux [W/m^2] https://www.goes-r.gov/products/baseline-DSR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "#pbar.set_description(f\"Processing {start_date} --> {temp_list[0][0]}\")\n",
    "\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "#make empty list to store the dates already sampled\n",
    "done_list = []\n",
    "metadata[forecast_param+'_'+str(hour)] = '' #create new column to store the data \n",
    "for idx in metadata.index: #takes first element in metadata list\n",
    "    start_date = metadata.date[idx]\n",
    "    date_index_list = metadata.index[metadata.date == start_date]#list with all the indexes of dates with the same date\n",
    "    if start_date not in done_list:#if data for the given date was already downloaded, this row will be skipped\n",
    "        temp_list = [[0] * days for i in range(len(date_index_list))]#make list of lists to store the values inside\n",
    "        done_list.append(start_date)#list of dates already samples\n",
    "        start_date = climf.get_start_date(start_date)#formate to time object\n",
    "        print(start_date)\n",
    "        for x in range(days):\n",
    "            count = 0\n",
    "            #x = x*2 (if we want to take only every second day)\n",
    "            day_date = start_date - timedelta(days=x+before)\n",
    "            #ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "            ds, stop = climf.get_ds_aws_array(day_date, hour,param_layer, forecast_param)#getting the temperature array for the specified date\n",
    "            for index in date_index_list:\n",
    "                x_grid = metadata.x_grid[index]\n",
    "                y_grid = metadata.y_grid[index]\n",
    "                if stop == True:\n",
    "                    temp_list[count][x] = np.nan\n",
    "                else:\n",
    "                    temp_list[count][x] = ds[x_grid][y_grid]\n",
    "                count += 1\n",
    "                if x == days-1 and index == date_index_list[len(date_index_list)-1]:#if condition is met put the values in the metadata file\n",
    "                    for i in range(len(temp_list)):                    \n",
    "                        metadata[forecast_param+'_'+str(hour)].loc[date_index_list[i]] = temp_list[i] #not index but  \n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.to_csv(f'../data/{forecast_param}_{str(hour)}_{str(before)}_{str(before+1)}_d_before.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad948ff7b48983452e55733fd71e7df6f615a0b1ed05e1cd9f8bab22d77c40aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
