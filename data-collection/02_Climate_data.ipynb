{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NOAA HRRR is a real-time 3km resolution, hourly updated, cloud-resolving, convection-allowing atmospheric model, initialized by 3km grids with 3km radar assimilation.\n",
    "\n",
    "This notebook provides an example of accessing HRRR data, including (1) finding the data file corresponding to a date and time, (2) retrieving a portion of that file from blob storage which includes the surface temperature variable, (3) opening the file using the xarray library, and (4) rendering an image of the forecast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is documented at http://aka.ms/ai4edata-hrrr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import climatedata_functions as climf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = climf.get_ds()#only words with recent dates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make metadafile with gridpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranform coordinates for longitude\n",
    "metadata['longitude_trans'] = metadata['longitude']+360 \n",
    "#add columns for gridpoints\n",
    "metadata['x_grid'] = ''\n",
    "metadata['y_grid'] = ''\n",
    "\n",
    "#make new metadatafile and save as cvs \n",
    "#metadata_new = climf.save_grids(metadata.head(), ds) #(takes approx 6 minutes)\n",
    "#metadata_new.to_csv('../data/metadata_grids.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load new metadata file that includes the gridpoints\n",
    "metadata = pd.read_csv(\"../data/metadata_grids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>date</th>\n",
       "      <th>split</th>\n",
       "      <th>longitude_trans</th>\n",
       "      <th>x_grid</th>\n",
       "      <th>y_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aabm</td>\n",
       "      <td>39.080319</td>\n",
       "      <td>-86.430867</td>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>train</td>\n",
       "      <td>273.569133</td>\n",
       "      <td>570</td>\n",
       "      <td>1217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aabn</td>\n",
       "      <td>36.559700</td>\n",
       "      <td>-121.510000</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>test</td>\n",
       "      <td>238.490000</td>\n",
       "      <td>550</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aacd</td>\n",
       "      <td>35.875083</td>\n",
       "      <td>-78.878434</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>train</td>\n",
       "      <td>281.121566</td>\n",
       "      <td>488</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aaee</td>\n",
       "      <td>35.487000</td>\n",
       "      <td>-79.062133</td>\n",
       "      <td>2016-08-24</td>\n",
       "      <td>train</td>\n",
       "      <td>280.937867</td>\n",
       "      <td>473</td>\n",
       "      <td>1453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aaff</td>\n",
       "      <td>38.049471</td>\n",
       "      <td>-99.827001</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>train</td>\n",
       "      <td>260.172999</td>\n",
       "      <td>513</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>aafl</td>\n",
       "      <td>39.474744</td>\n",
       "      <td>-86.898353</td>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>train</td>\n",
       "      <td>273.101647</td>\n",
       "      <td>583</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>aafp</td>\n",
       "      <td>35.647742</td>\n",
       "      <td>-79.271782</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>train</td>\n",
       "      <td>280.728218</td>\n",
       "      <td>478</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>aagm</td>\n",
       "      <td>35.906885</td>\n",
       "      <td>-79.132962</td>\n",
       "      <td>2020-06-10</td>\n",
       "      <td>train</td>\n",
       "      <td>280.867038</td>\n",
       "      <td>488</td>\n",
       "      <td>1447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>aahy</td>\n",
       "      <td>35.726522</td>\n",
       "      <td>-79.125458</td>\n",
       "      <td>2014-08-12</td>\n",
       "      <td>train</td>\n",
       "      <td>280.874542</td>\n",
       "      <td>481</td>\n",
       "      <td>1449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>aaia</td>\n",
       "      <td>35.980000</td>\n",
       "      <td>-78.791686</td>\n",
       "      <td>2018-06-27</td>\n",
       "      <td>train</td>\n",
       "      <td>281.208314</td>\n",
       "      <td>493</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   uid   latitude   longitude        date  split  \\\n",
       "0           0  aabm  39.080319  -86.430867  2018-05-14  train   \n",
       "1           1  aabn  36.559700 -121.510000  2016-08-31   test   \n",
       "2           2  aacd  35.875083  -78.878434  2020-11-19  train   \n",
       "3           3  aaee  35.487000  -79.062133  2016-08-24  train   \n",
       "4           4  aaff  38.049471  -99.827001  2019-07-23  train   \n",
       "5           5  aafl  39.474744  -86.898353  2021-08-23  train   \n",
       "6           6  aafp  35.647742  -79.271782  2017-11-15  train   \n",
       "7           7  aagm  35.906885  -79.132962  2020-06-10  train   \n",
       "8           8  aahy  35.726522  -79.125458  2014-08-12  train   \n",
       "9           9  aaia  35.980000  -78.791686  2018-06-27  train   \n",
       "\n",
       "   longitude_trans  x_grid  y_grid  \n",
       "0       273.569133     570    1217  \n",
       "1       238.490000     550     192  \n",
       "2       281.121566     488    1455  \n",
       "3       280.937867     473    1453  \n",
       "4       260.172999     513     831  \n",
       "5       273.101647     583    1202  \n",
       "6       280.728218     478    1445  \n",
       "7       280.867038     488    1447  \n",
       "8       280.874542     481    1449  \n",
       "9       281.208314     493    1457  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get temperatures for gridpoints"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function that gets the mean/median temperature for one date for all the places sampled at that date (to save time) and the previos x days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['temp'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janataumer/neue_fische/tick-tick-bloom/.venv/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-08-31\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     temp_list[count][x] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mna\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 32\u001b[0m     temp_list[count][x] \u001b[39m=\u001b[39m ds[x_grid][y_grid]\n\u001b[1;32m     33\u001b[0m count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m days\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m index \u001b[39m==\u001b[39m date_index_list[\u001b[39mlen\u001b[39m(date_index_list)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\u001b[39m#if condition is met put the values in the metadata file\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "start_date = climf.get_start_date(metadata.date[0])\n",
    "date_index_list = metadata.index[metadata.date == start_date]\n",
    "#print(date_index_list)\n",
    "temp_list = []\n",
    "done_list = []\n",
    "days = 7\n",
    "z = False\n",
    "for idx,row in enumerate(metadata.index): #takes first element in metadata list\n",
    "    #print(row, idx)\n",
    "    start_date = metadata.date[idx]\n",
    "    date_index_list = metadata.index[metadata.date == start_date]#list with all the indexes of dates with the same date\n",
    "    #print(date_index_list)\n",
    "    if start_date not in done_list:#only do if this date wasnt used before\n",
    "        temp_list = [[0] * days for i in range(len(date_index_list))]#make list of lists to store the values inside\n",
    "        #print(len(temp_list), len(temp_list[0]))\n",
    "        done_list.append(start_date)#list of dates already samples\n",
    "        start_date = climf.get_start_date(start_date)#formate to time object\n",
    "        print(start_date)\n",
    "        for x in range(days):\n",
    "            count = 0\n",
    "            day_date = start_date - timedelta(days=x)\n",
    "            ds = climf.get_ds_aws(day_date)#getting the temperature array for the specified date\n",
    "            for index in date_index_list:\n",
    "                x_grid = metadata.x_grid[index]\n",
    "                y_grid = metadata.y_grid[index]\n",
    "                if z == True:\n",
    "                    temp_list[count][x] = 'na'\n",
    "                else:\n",
    "                    temp_list[count][x] = ds[x_grid][y_grid]\n",
    "                count += 1\n",
    "                if x == days-1 and index == date_index_list[len(date_index_list)-1]:#if condition is met put the values in the metadata file\n",
    "                    for i in range(len(temp_list)):                    \n",
    "                        metadata.temp.loc[date_index_list[i]] = temp_list[i] #not index but \n",
    "        #if idx == 0:\n",
    "        #    break  \n",
    "    else:\n",
    "        continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import io\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import requests\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "import tempfile\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = climf.get_start_date('2016-08-27')\n",
    "#ds = climf.get_ds_aws(start_date)\n",
    "\n",
    "\n",
    "#blob_container = \"https://noaahrrr.blob.core.windows.net/hrrr\"\n",
    "sector = \"conus\"\n",
    "yesterday = day_date\n",
    "cycle = 1 \n",
    "forecast_hour = 1   # offset from cycle time\n",
    "product = \"wrfsfcf\" # 2D surface levels\n",
    "# Put it all together\n",
    "file_path = f\"hrrr.t{cycle:02}z.{product}{forecast_hour:02}.grib2\"\n",
    "url = f\"https://noaa-hrrr-bdp-pds.s3.amazonaws.com/hrrr.{yesterday:%Y%m%d}/{sector}/{file_path}\"\n",
    "\n",
    "r = requests.get(f\"{url}.idx\")\n",
    "idx = r.text.splitlines()\n",
    "\n",
    "print(url)\n",
    "print(r)\n",
    "print(idx)\n",
    "\n",
    "sfc_temp_idx = [l for l in idx if \":TMP:surface\" in l][0].split(\":\")\n",
    "# Pluck the byte offset from this line, plus the beginning offset of the next line\n",
    "line_num = int(sfc_temp_idx[0])\n",
    "range_start = sfc_temp_idx[1]\n",
    "# The line number values are 1-indexed, so we don't need to increment it to get the next list index,\n",
    "# but check we're not already reading the last line\n",
    "next_line = idx[line_num].split(':') if line_num < len(idx) else None\n",
    "# Pluck the start of the next byte offset, or nothing if we were on the last line\n",
    "range_end = next_line[1] if next_line else None\n",
    "\n",
    "file = tempfile.NamedTemporaryFile(prefix=\"tmp_\", delete=False)\n",
    "headers = {\"Range\": f\"bytes={range_start}-{range_end}\"}\n",
    "resp = requests.get(url, headers=headers, stream=True)\n",
    "with file as f:\n",
    "    f.write(resp.content)\n",
    "ds = xr.open_dataset(file.name, engine='cfgrib', \n",
    "                    backend_kwargs={'indexpath':''})\n",
    "return ds.t.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://noaa-hrrr-bdp-pds.s3.amazonaws.com/hrrr.20160827/conus/hrrr.t01z.wrfsfcf01.grib2\n",
    "\n",
    "https://noaa-hrrr-bdp-pds.s3.amazonaws.com/hrrr.20160827/conus/hrrr.t12z.wrfsfcf01.grib2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in len(temp_list): \n",
    "    print(i)\n",
    "\n",
    "date_index_list\n",
    "date_index_list[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = metadata.date[0]\n",
    "date_index_list = metadata.index[metadata.date == start_date]\n",
    "date_index_list.index == date_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.y_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x,y)\n",
    "#ds[x][y].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "start_date = climf.get_start_date(metadata.date[0])\n",
    "temp_list = []\n",
    "days = 2\n",
    "\n",
    "for row in range(len(metadata[0].uid)):\n",
    "    start_date = metadata.date[row]\n",
    "    date_index_list = metadata.index[metadata.date == date]\n",
    "    done_list.append(start_date)\n",
    "    start_date = climf.get_start_date(start_date)\n",
    "    temp_array = [[0] * len(start_date) for i in range(days)]\n",
    "    print(temp_array)\n",
    "    for x in range(days):\n",
    "        day_date = start_date - timedelta(days=x)\n",
    "        print(day_date)\n",
    "        ds = climf.get_temp_aws(day_date)##input changed\n",
    "        for idx in date_index_list:\n",
    "            \n",
    "\n",
    "            temp_list.append(temperature)\n",
    "    temp_list\n",
    "\n",
    "\n",
    "metadata.x_grid[0] ,metadata.y_grid[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad948ff7b48983452e55733fd71e7df6f615a0b1ed05e1cd9f8bab22d77c40aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
